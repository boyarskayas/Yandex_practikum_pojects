# Определение токсичности комментариев


# Цель проекта


Требуется инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.
Для этого необходимо обучить модель классифицировать комментарии на позитивные и негативные на основании набора данных с разметкой о токсичности правок. 

Необходимо построить модель со значением метрики качества F1 не менее 0.75.

# Описание данных

Столбец `text` содержит текст комментария  
Столбец `toxic` содержит целевой признак


# Навыки и инструменты: 

 `NLP`, `Python`, `Pandas`, `NumPy`, `ScLearn`, `nltk`, `SpaCy`, `tf-idf`
